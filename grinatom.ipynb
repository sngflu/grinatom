{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9604233,"sourceType":"datasetVersion","datasetId":5827438}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nfrom collections import defaultdict\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\nimport spacy\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.utils import resample\n\nimport pickle\nimport joblib\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout, Bidirectional\nfrom tensorflow.keras.utils import to_categorical\n\nfrom gensim.models import Word2Vec, FastText\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-16T16:33:21.391104Z","iopub.execute_input":"2024-10-16T16:33:21.391386Z","iopub.status.idle":"2024-10-16T16:34:02.806912Z","shell.execute_reply.started":"2024-10-16T16:33:21.391354Z","shell.execute_reply":"2024-10-16T16:34:02.805869Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"root = '/kaggle/input/imdb-grinatom/aclImdb_v1/aclImdb/'","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:02.808776Z","iopub.execute_input":"2024-10-16T16:34:02.809485Z","iopub.status.idle":"2024-10-16T16:34:02.813762Z","shell.execute_reply.started":"2024-10-16T16:34:02.809447Z","shell.execute_reply":"2024-10-16T16:34:02.812863Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# with open(root+'train/pos/1000_8.txt') as file:\n#     review = file.read()\n#     print(review)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:02.814913Z","iopub.execute_input":"2024-10-16T16:34:02.815284Z","iopub.status.idle":"2024-10-16T16:34:02.825114Z","shell.execute_reply.started":"2024-10-16T16:34:02.815251Z","shell.execute_reply":"2024-10-16T16:34:02.824196Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# def create_csv(data_dir, output_csv):\n#     reviews = []\n#     ratings = []\n#     sentiments = []\n\n#     for sentiment in ['pos', 'neg']:\n#         folder_path = os.path.join(data_dir, sentiment)\n#         for filename in os.listdir(data_dir):\n#             if filename.endswith(\".txt\"):\n#                 rating = int(filename.split('_')[1].split('.')[0])\n\n#                 with open(os.path.join(data_dir, filename), 'r', encoding='utf-8') as file:\n#                     review = file.read()\n\n#                 reviews.append(review)\n#                 ratings.append(rating)\n#                 sentiments.append(sentiment)\n\n#     df = pd.DataFrame({\n#         'review': reviews,\n#         'rating': ratings,\n#         'sentiment': sentiments\n#     })\n\n#     df.to_csv(output_csv, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:02.827370Z","iopub.execute_input":"2024-10-16T16:34:02.827703Z","iopub.status.idle":"2024-10-16T16:34:02.836000Z","shell.execute_reply.started":"2024-10-16T16:34:02.827670Z","shell.execute_reply":"2024-10-16T16:34:02.835168Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# train_dir = root + 'train'\n# test_dir = root + 'test'\n\n# create_csv(train_dir, 'train.csv')\n# create_csv(test_dir, 'test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:02.837029Z","iopub.execute_input":"2024-10-16T16:34:02.837318Z","iopub.status.idle":"2024-10-16T16:34:02.850824Z","shell.execute_reply.started":"2024-10-16T16:34:02.837287Z","shell.execute_reply":"2024-10-16T16:34:02.849962Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# create_csv('/kaggle/input/imdb-grinatom/aclImdb/train/unsup', 'unsup.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:02.851917Z","iopub.execute_input":"2024-10-16T16:34:02.852244Z","iopub.status.idle":"2024-10-16T16:34:02.860967Z","shell.execute_reply.started":"2024-10-16T16:34:02.852212Z","shell.execute_reply":"2024-10-16T16:34:02.860146Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/imdb-grinatom/cleaned_train.csv')\ntest_df = pd.read_csv('/kaggle/input/imdb-grinatom/cleaned_test.csv')\ntrain_ddf = pd.read_csv('/kaggle/input/imdb-grinatom/train.csv')\ntest_ddf = pd.read_csv('/kaggle/input/imdb-grinatom/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:02.862192Z","iopub.execute_input":"2024-10-16T16:34:02.862811Z","iopub.status.idle":"2024-10-16T16:34:05.181645Z","shell.execute_reply.started":"2024-10-16T16:34:02.862770Z","shell.execute_reply":"2024-10-16T16:34:05.180373Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def count_words(text):\n    return len(text.split())\n\ntrain_word_counts = train_df['review'].apply(count_words)\ntest_word_counts = test_df['review'].apply(count_words)\n\ntrain_mean_words = train_word_counts.mean()\ntrain_max_words = train_word_counts.max()\n\ntest_mean_words = test_word_counts.mean()\ntest_max_words = test_word_counts.max()\n\nprint(f\"Train DataFrame:\")\nprint(f\"Среднее число слов: {train_mean_words}\")\nprint(f\"Максимальное число слов: {train_max_words}\")\n\nprint(f\"Test DataFrame:\")\nprint(f\"Среднее число слов: {test_mean_words}\")\nprint(f\"Максимальное число слов: {test_max_words}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:05.182970Z","iopub.execute_input":"2024-10-16T16:34:05.183287Z","iopub.status.idle":"2024-10-16T16:34:05.547602Z","shell.execute_reply.started":"2024-10-16T16:34:05.183256Z","shell.execute_reply":"2024-10-16T16:34:05.546569Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Train DataFrame:\nСреднее число слов: 105.30524\nМаксимальное число слов: 1287\nTest DataFrame:\nСреднее число слов: 102.82496\nМаксимальное число слов: 1052\n","output_type":"stream"}]},{"cell_type":"code","source":"all_texts = train_df['review']\n\ntokenizer = Tokenizer(oov_token='<OOV>')\ntokenizer.fit_on_texts(all_texts)\n\nword_counts = tokenizer.word_counts\n\ndef calculate_coverage(word_counts, num_words):\n    total_words = sum(word_counts.values())\n    top_words = sorted(word_counts.items(), key=lambda item: item[1], reverse=True)[:num_words]\n    top_words_count = sum(count for word, count in top_words)\n    coverage = top_words_count / total_words\n    return coverage\n\ncoverages = {}\nfor num_words in [5000, 7500, 10000, 20000, 30000, 40000, 50000]:\n    coverage = calculate_coverage(word_counts, num_words)\n    coverages[num_words] = coverage\n    print(f\"Coverage with {num_words} words: {coverage:.2%}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:05.548748Z","iopub.execute_input":"2024-10-16T16:34:05.549069Z","iopub.status.idle":"2024-10-16T16:34:08.174002Z","shell.execute_reply.started":"2024-10-16T16:34:05.549036Z","shell.execute_reply":"2024-10-16T16:34:08.173051Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Coverage with 5000 words: 85.41%\nCoverage with 7500 words: 89.85%\nCoverage with 10000 words: 92.48%\nCoverage with 20000 words: 97.01%\nCoverage with 30000 words: 98.53%\nCoverage with 40000 words: 99.18%\nCoverage with 50000 words: 99.56%\n","output_type":"stream"}]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n\nsns.set(style=\"whitegrid\")\n\ndef plot_histogram(ax, pos_data, neg_data, title):\n    sns.histplot(pos_data, bins=10, kde=False, ax=ax, color='green', label='Positive')\n    sns.histplot(neg_data, bins=10, kde=False, ax=ax, color='red', label='Negative')\n    ax.set_title(title)\n    ax.set_xlabel('Rating')\n    ax.set_ylabel('Count')\n    ax.set_xticks(range(0, 11))\n    ax.legend()\n\nplot_histogram(axs[0], train_df[train_df['sentiment'] == 'pos']['rating'], train_df[train_df['sentiment'] == 'neg']['rating'], 'Train - Reviews Rating Distribution')\nplot_histogram(axs[1], test_df[test_df['sentiment'] == 'pos']['rating'], test_df[test_df['sentiment'] == 'neg']['rating'], 'Test - Reviews Rating Distribution')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:08.175315Z","iopub.execute_input":"2024-10-16T16:34:08.175629Z","iopub.status.idle":"2024-10-16T16:34:09.038113Z","shell.execute_reply.started":"2024-10-16T16:34:08.175596Z","shell.execute_reply":"2024-10-16T16:34:09.037219Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1400x600 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\n\ncontractions_dict = {\n    \"aren't\": \"are not\",\n    \"can't\": \"can not\",\n    \"could've\": \"could have\",\n    \"couldn't\": \"could not\",\n    \"didn't\": \"did not\",\n    \"doesn't\": \"does not\",\n    \"don't\": \"do not\",\n    \"he'd\": \"he would\",\n    \"he'll\": \"he will\",\n    \"he's\": \"he is\",\n    \"i'd\": \"i would\",\n    \"i'll\": \"i will\",\n    \"i'm\": \"i am\",\n    \"i've\": \"i have\",\n    \"isn't\": \"is not\",\n    \"it'll\": \"it will\",\n    \"it's\": \"it is\",\n    \"let's\": \"let us\",\n    \"might've\": \"might have\",\n    \"must've\": \"must have\",\n    \"mustn't\": \"must not\",\n    \"should've\": \"should have\",\n    \"shouldn't\": \"should not\",\n    \"that's\": \"that is\",\n    \"there's\": \"there is\",\n    \"they'd\": \"they would\",\n    \"they'll\": \"they will\",\n    \"they're\": \"they are\",\n    \"they've\": \"they have\",\n    \"we'd\": \"we would\",\n    \"we'll\": \"we will\",\n    \"we're\": \"we are\",\n    \"we've\": \"we have\",\n    \"weren't\": \"were not\",\n    \"what's\": \"what is\",\n    \"where's\": \"where is\",\n    \"who's\": \"who is\",\n    \"won't\": \"will not\",\n    \"would've\": \"would have\",\n    \"wouldn't\": \"would not\",\n    \"you've\": \"you have\",\n}\n\ndef expand_contractions(text, contractions_dict):\n    for contraction, expanded in contractions_dict.items():\n        text = re.sub(r\"\\b{}\\b\".format(contraction), expanded, text)\n    return text\n\ndef remove_html_tags(text):\n    clean = re.compile('<.*?>')\n    return re.sub(clean, ' ', text)\n\ndef clean_text(text):\n    text = remove_html_tags(text)\n    \n    text = text.lower()\n    \n    text = expand_contractions(text, contractions_dict)\n    \n    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n    \n    doc = nlp(text)\n    \n    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n    \n    tokens = [token for token in tokens if len(token) > 1 or token.isdigit()]\n    \n    clean_text = ' '.join(tokens)\n    \n    clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n    \n    return clean_text","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:09.043284Z","iopub.execute_input":"2024-10-16T16:34:09.043572Z","iopub.status.idle":"2024-10-16T16:34:10.231780Z","shell.execute_reply.started":"2024-10-16T16:34:09.043541Z","shell.execute_reply":"2024-10-16T16:34:10.230948Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"sample_text = \"\"\"I loved this movie from beginning to end.I am a musician and i let drugs get in the way of my some of the things i used to love(skateboarding,drawing) but my friends were always there for me.Music was like my rehab,life support,and my drug.It changed my life.I can totally relate to this movie and i wish there was more i could say.This movie left me speechless to be honest.I just saw it on the Ifc channel.I usually hate having satellite but this was a perk of having satellite.The ifc channel shows some really great movies and without it I never would have found this movie.Im not a big fan of the international films because i find that a lot of the don't do a very good job on translating lines.I mean the obvious language barrier leaves you to just believe thats what they are saying but its not that big of a deal i guess.I almost never got to see this AMAZING movie.Good thing i stayed up for it instead of going to bed..well earlier than usual.lol.I hope you all enjoy the hell of this movie and Love this movie just as much as i did.I wish i could type this all in caps but its again the rules i guess thats shouting but it would really show my excitement for the film.I Give It Three Thumbs Way Up!<br /><br />This Movie Blew ME AWAY!\"\"\"\ncleaned_text = clean_text(sample_text)\nprint(cleaned_text)  ","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:10.232857Z","iopub.execute_input":"2024-10-16T16:34:10.233177Z","iopub.status.idle":"2024-10-16T16:34:10.312533Z","shell.execute_reply.started":"2024-10-16T16:34:10.233144Z","shell.execute_reply":"2024-10-16T16:34:10.311437Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"love movie begin end musician let drug way thing love skateboard draw friend music like rehab life support drug change life totally relate movie wish movie leave speechless honest see ifc channel usually hate have satellite perk have satellite ifc channel show great movie find movie big fan international film find lot good job translate line mean obvious language barrier leave believe say big deal guess get amazing movie good thing stay instead go bed early usual lol hope enjoy hell movie love movie wish type cap rule guess shout excitement film thumb way movie blow away\n","output_type":"stream"}]},{"cell_type":"code","source":"# train_df['review'] = train_df['review'].apply(clean_text)\n# test_df['review'] = test_df['review'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:10.313725Z","iopub.execute_input":"2024-10-16T16:34:10.314066Z","iopub.status.idle":"2024-10-16T16:34:10.318512Z","shell.execute_reply.started":"2024-10-16T16:34:10.314021Z","shell.execute_reply":"2024-10-16T16:34:10.317524Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# train_df.to_csv('cleaned_train.csv', index=False)\n# test_df.to_csv('cleaned_test.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:10.319674Z","iopub.execute_input":"2024-10-16T16:34:10.320001Z","iopub.status.idle":"2024-10-16T16:34:10.329445Z","shell.execute_reply.started":"2024-10-16T16:34:10.319967Z","shell.execute_reply":"2024-10-16T16:34:10.328668Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# classic","metadata":{}},{"cell_type":"code","source":"# cleaned_train_df = pd.read_csv('/kaggle/working/cleaned_train.csv')\n# cleaned_test_df = pd.read_csv('/kaggle/working/cleaned_test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:10.330441Z","iopub.execute_input":"2024-10-16T16:34:10.330746Z","iopub.status.idle":"2024-10-16T16:34:10.338987Z","shell.execute_reply.started":"2024-10-16T16:34:10.330716Z","shell.execute_reply":"2024-10-16T16:34:10.338233Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"all_data = pd.concat([train_df, test_df])","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:10.339976Z","iopub.execute_input":"2024-10-16T16:34:10.340324Z","iopub.status.idle":"2024-10-16T16:34:10.352092Z","shell.execute_reply.started":"2024-10-16T16:34:10.340285Z","shell.execute_reply":"2024-10-16T16:34:10.351355Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"vectorizer = CountVectorizer(max_features=20000)\nX = vectorizer.fit_transform(all_data['review'])","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:10.353159Z","iopub.execute_input":"2024-10-16T16:34:10.353481Z","iopub.status.idle":"2024-10-16T16:34:16.025607Z","shell.execute_reply.started":"2024-10-16T16:34:10.353448Z","shell.execute_reply":"2024-10-16T16:34:16.024568Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"X_train = X[:len(train_df)]\nX_test = X[len(train_df):]\n\ny_train = train_df['rating']\ny_test = test_df['rating']","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:16.026783Z","iopub.execute_input":"2024-10-16T16:34:16.027138Z","iopub.status.idle":"2024-10-16T16:34:16.089297Z","shell.execute_reply.started":"2024-10-16T16:34:16.027104Z","shell.execute_reply":"2024-10-16T16:34:16.088263Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"min_samples = y_train.value_counts().min()\n\ndef undersample(df, target_column, min_samples):\n    undersampled_dfs = []\n    for rating in df[target_column].unique():\n        rating_df = df[df[target_column] == rating]\n        undersampled_df = resample(rating_df, replace=False, n_samples=min_samples, random_state=42)\n        undersampled_dfs.append(undersampled_df)\n    return pd.concat(undersampled_dfs)\n\nundersampled_train_df = undersample(train_df, 'rating', min_samples)\n\nX_train_undersampled = vectorizer.transform(undersampled_train_df['review'])\ny_train_undersampled = undersampled_train_df['rating']\n\nundersampled_test_df = undersample(test_df, 'rating', min_samples)\n\nX_test_undersampled = vectorizer.transform(undersampled_test_df['review'])\ny_test_undersampled = undersampled_test_df['rating']","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:16.090517Z","iopub.execute_input":"2024-10-16T16:34:16.090831Z","iopub.status.idle":"2024-10-16T16:34:20.874248Z","shell.execute_reply.started":"2024-10-16T16:34:16.090799Z","shell.execute_reply":"2024-10-16T16:34:20.873457Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"models = {\n    'Logistic Regression': LogisticRegression(max_iter=1000, C=1.0, solver='saga', random_state=42),\n    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n    'Support Vector Machine': SVC(C=1.0, kernel='linear', random_state=42)\n}","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:20.875398Z","iopub.execute_input":"2024-10-16T16:34:20.875765Z","iopub.status.idle":"2024-10-16T16:34:20.881959Z","shell.execute_reply.started":"2024-10-16T16:34:20.875725Z","shell.execute_reply":"2024-10-16T16:34:20.881059Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train_and_evaluate_models(models, X_train, y_train, X_test, y_test, save_dir=None):\n    if not os.path.exists(save_dir):\n        os.makedirs(save_dir)\n\n    for name, model in models.items():\n        print(f\"Training {name}...\")\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n\n        accuracy = accuracy_score(y_test, y_pred)\n        print(f\"Accuracy: {accuracy:,.3f}\")\n\n        print(\"Classification Report:\")\n        print(classification_report(y_test, y_pred))\n        print(\"\\n\")\n\n        model_path = os.path.join(save_dir, f\"{name.replace(' ', '_')}.joblib\")\n        joblib.dump(model, model_path)\n        print(f\"Model {name} saved to {model_path}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:20.883147Z","iopub.execute_input":"2024-10-16T16:34:20.883433Z","iopub.status.idle":"2024-10-16T16:34:20.894674Z","shell.execute_reply.started":"2024-10-16T16:34:20.883404Z","shell.execute_reply":"2024-10-16T16:34:20.893942Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"tfidf = TfidfVectorizer(max_features=20000)\n\nX_train_tfidf = tfidf.fit_transform(train_df['review'])\nX_test_tfidf = tfidf.transform(test_df['review'])  \n\nwith open('tfidf.pkl', 'wb') as f:\n    pickle.dump(tfidf, f)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:20.896099Z","iopub.execute_input":"2024-10-16T16:34:20.896411Z","iopub.status.idle":"2024-10-16T16:34:27.202720Z","shell.execute_reply.started":"2024-10-16T16:34:20.896380Z","shell.execute_reply":"2024-10-16T16:34:27.201850Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_and_evaluate_models(models, X_train, y_train, X_test, y_test, 'default_mc8_data')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:34:27.203874Z","iopub.execute_input":"2024-10-16T16:34:27.204216Z","iopub.status.idle":"2024-10-16T16:55:26.092434Z","shell.execute_reply.started":"2024-10-16T16:34:27.204182Z","shell.execute_reply":"2024-10-16T16:55:26.091452Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Training Logistic Regression...\nAccuracy: 0.359\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.55      0.63      0.59      5022\n           2       0.18      0.15      0.17      2302\n           3       0.22      0.19      0.20      2541\n           4       0.25      0.26      0.26      2635\n           7       0.24      0.22      0.23      2307\n           8       0.23      0.21      0.22      2850\n           9       0.20      0.16      0.18      2344\n          10       0.50      0.56      0.53      4999\n\n    accuracy                           0.36     25000\n   macro avg       0.29      0.30      0.29     25000\nweighted avg       0.34      0.36      0.35     25000\n\n\n\nModel Logistic Regression saved to default_mc8_data/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.353\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.34      0.94      0.49      5022\n           2       0.00      0.00      0.00      2302\n           3       0.00      0.00      0.00      2541\n           4       1.00      0.00      0.00      2635\n           7       0.00      0.00      0.00      2307\n           8       0.25      0.00      0.00      2850\n           9       0.00      0.00      0.00      2344\n          10       0.38      0.82      0.52      4999\n\n    accuracy                           0.35     25000\n   macro avg       0.25      0.22      0.13     25000\nweighted avg       0.28      0.35      0.20     25000\n\n\n\nModel Random Forest saved to default_mc8_data/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.373\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.45      0.78      0.57      5022\n           2       0.22      0.03      0.06      2302\n           3       0.25      0.05      0.09      2541\n           4       0.29      0.16      0.21      2635\n           7       0.28      0.13      0.18      2307\n           8       0.22      0.12      0.15      2850\n           9       0.17      0.02      0.03      2344\n          10       0.37      0.82      0.51      4999\n\n    accuracy                           0.37     25000\n   macro avg       0.28      0.26      0.23     25000\nweighted avg       0.31      0.37      0.29     25000\n\n\n\nModel Gradient Boosting saved to default_mc8_data/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.330\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.51      0.60      0.55      5022\n           2       0.17      0.18      0.17      2302\n           3       0.20      0.19      0.19      2541\n           4       0.24      0.24      0.24      2635\n           7       0.23      0.24      0.23      2307\n           8       0.21      0.22      0.22      2850\n           9       0.19      0.17      0.18      2344\n          10       0.51      0.43      0.46      4999\n\n    accuracy                           0.33     25000\n   macro avg       0.28      0.28      0.28     25000\nweighted avg       0.33      0.33      0.33     25000\n\n\n\nModel Support Vector Machine saved to default_mc8_data/Support_Vector_Machine.joblib\n\n","output_type":"stream"}]},{"cell_type":"code","source":"train_and_evaluate_models(models, X_train_undersampled, y_train_undersampled, X_test_undersampled, y_test_undersampled, 'undersampled_mc8_data')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T16:55:26.093632Z","iopub.execute_input":"2024-10-16T16:55:26.093929Z","iopub.status.idle":"2024-10-16T17:08:10.305757Z","shell.execute_reply.started":"2024-10-16T16:55:26.093897Z","shell.execute_reply":"2024-10-16T17:08:10.304787Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Training Logistic Regression...\nAccuracy: 0.290\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.43      0.47      0.45      2263\n           2       0.25      0.25      0.25      2263\n           3       0.24      0.22      0.23      2263\n           4       0.26      0.27      0.26      2263\n           7       0.28      0.24      0.26      2263\n           8       0.23      0.22      0.22      2263\n           9       0.25      0.26      0.26      2263\n          10       0.36      0.39      0.38      2263\n\n    accuracy                           0.29     18104\n   macro avg       0.29      0.29      0.29     18104\nweighted avg       0.29      0.29      0.29     18104\n\n\n\nModel Logistic Regression saved to undersampled_mc8_data/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.283\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.34      0.64      0.45      2263\n           2       0.24      0.17      0.20      2263\n           3       0.26      0.15      0.19      2263\n           4       0.27      0.15      0.19      2263\n           7       0.28      0.23      0.26      2263\n           8       0.22      0.12      0.16      2263\n           9       0.25      0.19      0.21      2263\n          10       0.28      0.62      0.39      2263\n\n    accuracy                           0.28     18104\n   macro avg       0.27      0.28      0.26     18104\nweighted avg       0.27      0.28      0.26     18104\n\n\n\nModel Random Forest saved to undersampled_mc8_data/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.280\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.38      0.54      0.45      2263\n           2       0.23      0.19      0.21      2263\n           3       0.25      0.15      0.19      2263\n           4       0.23      0.19      0.21      2263\n           7       0.26      0.28      0.27      2263\n           8       0.20      0.18      0.19      2263\n           9       0.26      0.25      0.26      2263\n          10       0.33      0.45      0.38      2263\n\n    accuracy                           0.28     18104\n   macro avg       0.27      0.28      0.27     18104\nweighted avg       0.27      0.28      0.27     18104\n\n\n\nModel Gradient Boosting saved to undersampled_mc8_data/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.278\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.40      0.48      0.43      2263\n           2       0.24      0.26      0.25      2263\n           3       0.22      0.22      0.22      2263\n           4       0.25      0.25      0.25      2263\n           7       0.26      0.25      0.25      2263\n           8       0.23      0.22      0.22      2263\n           9       0.24      0.22      0.23      2263\n          10       0.37      0.33      0.35      2263\n\n    accuracy                           0.28     18104\n   macro avg       0.28      0.28      0.28     18104\nweighted avg       0.28      0.28      0.28     18104\n\n\n\nModel Support Vector Machine saved to undersampled_mc8_data/Support_Vector_Machine.joblib\n\n","output_type":"stream"}]},{"cell_type":"code","source":"train_and_evaluate_models(models, X_train_tfidf, y_train, X_test_tfidf, y_test, 'tfidf_mc8_data')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T17:08:10.307196Z","iopub.execute_input":"2024-10-16T17:08:10.307585Z","iopub.status.idle":"2024-10-16T17:33:30.558751Z","shell.execute_reply.started":"2024-10-16T17:08:10.307543Z","shell.execute_reply":"2024-10-16T17:33:30.557786Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Training Logistic Regression...\nAccuracy: 0.411\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.51      0.81      0.63      5022\n           2       0.19      0.06      0.09      2302\n           3       0.25      0.12      0.16      2541\n           4       0.30      0.31      0.30      2635\n           7       0.30      0.21      0.25      2307\n           8       0.25      0.21      0.23      2850\n           9       0.22      0.05      0.09      2344\n          10       0.47      0.75      0.58      4999\n\n    accuracy                           0.41     25000\n   macro avg       0.31      0.31      0.29     25000\nweighted avg       0.35      0.41      0.36     25000\n\n\n\nModel Logistic Regression saved to tfidf_mc8_data/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.350\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.34      0.93      0.50      5022\n           2       0.00      0.00      0.00      2302\n           3       0.00      0.00      0.00      2541\n           4       0.00      0.00      0.00      2635\n           7       0.00      0.00      0.00      2307\n           8       1.00      0.00      0.00      2850\n           9       0.00      0.00      0.00      2344\n          10       0.36      0.81      0.50      4999\n\n    accuracy                           0.35     25000\n   macro avg       0.21      0.22      0.13     25000\nweighted avg       0.25      0.35      0.20     25000\n\n\n\nModel Random Forest saved to tfidf_mc8_data/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.372\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.46      0.76      0.58      5022\n           2       0.22      0.05      0.08      2302\n           3       0.24      0.07      0.11      2541\n           4       0.26      0.16      0.20      2635\n           7       0.28      0.15      0.20      2307\n           8       0.22      0.14      0.17      2850\n           9       0.17      0.03      0.05      2344\n          10       0.38      0.79      0.51      4999\n\n    accuracy                           0.37     25000\n   macro avg       0.28      0.27      0.24     25000\nweighted avg       0.31      0.37      0.30     25000\n\n\n\nModel Gradient Boosting saved to tfidf_mc8_data/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.402\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.52      0.77      0.62      5022\n           2       0.19      0.08      0.11      2302\n           3       0.22      0.14      0.18      2541\n           4       0.28      0.31      0.30      2635\n           7       0.29      0.24      0.26      2307\n           8       0.25      0.23      0.24      2850\n           9       0.22      0.06      0.09      2344\n          10       0.50      0.69      0.58      4999\n\n    accuracy                           0.40     25000\n   macro avg       0.31      0.32      0.30     25000\nweighted avg       0.35      0.40      0.36     25000\n\n\n\nModel Support Vector Machine saved to tfidf_mc8_data/Support_Vector_Machine.joblib\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# classic pos/neg","metadata":{}},{"cell_type":"code","source":"neg_train_df = train_df[train_df['rating'].between(1, 4)]\nneg_test_df = test_df[test_df['rating'].between(1, 4)]\npos_train_df = train_df[train_df['rating'].between(7, 10)]\npos_test_df = test_df[test_df['rating'].between(7, 10)]\n\nX_train_neg = vectorizer.transform(neg_train_df['review'])\nX_test_neg = vectorizer.transform(neg_test_df['review'])\nX_train_pos = vectorizer.transform(pos_train_df['review'])\nX_test_pos = vectorizer.transform(pos_test_df['review'])\n\ny_train_neg = neg_train_df['rating']\ny_test_neg = neg_test_df['rating']\ny_train_pos = pos_train_df['rating']\ny_test_pos = pos_test_df['rating']\n\nprint(\"Negative reviews (1-4):\")\ntrain_and_evaluate_models(models, X_train_neg, y_train_neg, X_test_neg, y_test_neg, 'bow_mc4_neg_data')\n\nprint(\"Positive reviews (7-10):\")\ntrain_and_evaluate_models(models, X_train_pos, y_train_pos, X_test_pos, y_test_pos, 'bow_mc4_pos_data')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T17:33:30.560174Z","iopub.execute_input":"2024-10-16T17:33:30.560557Z","iopub.status.idle":"2024-10-16T17:45:36.744490Z","shell.execute_reply.started":"2024-10-16T17:33:30.560513Z","shell.execute_reply":"2024-10-16T17:45:36.743496Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Negative reviews (1-4):\nTraining Logistic Regression...\nAccuracy: 0.419\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.57      0.64      0.61      5022\n           2       0.21      0.19      0.20      2302\n           3       0.27      0.23      0.25      2541\n           4       0.38      0.37      0.37      2635\n\n    accuracy                           0.42     12500\n   macro avg       0.36      0.36      0.36     12500\nweighted avg       0.40      0.42      0.41     12500\n\n\n\nModel Logistic Regression saved to bow_mc4_neg_data/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.403\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.40      1.00      0.57      5022\n           2       0.00      0.00      0.00      2302\n           3       1.00      0.00      0.00      2541\n           4       0.59      0.00      0.01      2635\n\n    accuracy                           0.40     12500\n   macro avg       0.50      0.25      0.15     12500\nweighted avg       0.49      0.40      0.23     12500\n\n\n\nModel Random Forest saved to bow_mc4_neg_data/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.458\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.48      0.92      0.63      5022\n           2       0.23      0.02      0.03      2302\n           3       0.30      0.05      0.09      2541\n           4       0.42      0.35      0.38      2635\n\n    accuracy                           0.46     12500\n   macro avg       0.36      0.34      0.28     12500\nweighted avg       0.38      0.46      0.36     12500\n\n\n\nModel Gradient Boosting saved to bow_mc4_neg_data/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.404\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.55      0.63      0.59      5022\n           2       0.20      0.20      0.20      2302\n           3       0.26      0.22      0.24      2541\n           4       0.38      0.32      0.35      2635\n\n    accuracy                           0.40     12500\n   macro avg       0.35      0.34      0.34     12500\nweighted avg       0.39      0.40      0.39     12500\n\n\n\nModel Support Vector Machine saved to bow_mc4_neg_data/Support_Vector_Machine.joblib\n\nPositive reviews (7-10):\nTraining Logistic Regression...\nAccuracy: 0.397\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.36      0.33      0.35      2307\n           8       0.27      0.25      0.26      2850\n           9       0.22      0.18      0.20      2344\n          10       0.53      0.61      0.57      4999\n\n    accuracy                           0.40     12500\n   macro avg       0.35      0.34      0.34     12500\nweighted avg       0.38      0.40      0.39     12500\n\n\n\nModel Logistic Regression saved to bow_mc4_pos_data/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.400\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.54      0.00      0.01      2307\n           8       0.19      0.00      0.00      2850\n           9       0.00      0.00      0.00      2344\n          10       0.40      1.00      0.57      4999\n\n    accuracy                           0.40     12500\n   macro avg       0.28      0.25      0.15     12500\nweighted avg       0.30      0.40      0.23     12500\n\n\n\nModel Random Forest saved to bow_mc4_pos_data/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.441\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.42      0.24      0.31      2307\n           8       0.30      0.15      0.20      2850\n           9       0.24      0.03      0.05      2344\n          10       0.47      0.89      0.61      4999\n\n    accuracy                           0.44     12500\n   macro avg       0.36      0.33      0.29     12500\nweighted avg       0.38      0.44      0.36     12500\n\n\n\nModel Gradient Boosting saved to bow_mc4_pos_data/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.358\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.31      0.37      0.33      2307\n           8       0.25      0.27      0.26      2850\n           9       0.21      0.20      0.21      2344\n          10       0.54      0.48      0.51      4999\n\n    accuracy                           0.36     12500\n   macro avg       0.33      0.33      0.33     12500\nweighted avg       0.37      0.36      0.36     12500\n\n\n\nModel Support Vector Machine saved to bow_mc4_pos_data/Support_Vector_Machine.joblib\n\n","output_type":"stream"}]},{"cell_type":"code","source":"min_samples_neg = min(neg_train_df['rating'].value_counts().min(), neg_test_df['rating'].value_counts().min())\nmin_samples_pos = min(pos_train_df['rating'].value_counts().min(), pos_test_df['rating'].value_counts().min())\n\nundersampled_neg_train_df = undersample(neg_train_df, 'rating', min_samples_neg)\nundersampled_neg_test_df = undersample(neg_test_df, 'rating', min_samples_neg)\nundersampled_pos_train_df = undersample(pos_train_df, 'rating', min_samples_pos)\nundersampled_pos_test_df = undersample(pos_test_df, 'rating', min_samples_pos)\n\nX_train_neg_undersampled = vectorizer.transform(undersampled_neg_train_df['review'])\nX_test_neg_undersampled = vectorizer.transform(undersampled_neg_test_df['review'])\nX_train_pos_undersampled = vectorizer.transform(undersampled_pos_train_df['review'])\nX_test_pos_undersampled = vectorizer.transform(undersampled_pos_test_df['review'])\n\ny_train_neg_undersampled = undersampled_neg_train_df['rating']\ny_test_neg_undersampled = undersampled_neg_test_df['rating']\ny_train_pos_undersampled = undersampled_pos_train_df['rating']\ny_test_pos_undersampled = undersampled_pos_test_df['rating']\n\nprint(\"Undersampled negative reviews (1-4):\")\ntrain_and_evaluate_models(models, X_train_neg_undersampled, y_train_neg_undersampled, X_test_neg_undersampled, y_test_neg_undersampled, 'bow_undersampled_mc4_neg_data')\n\nprint(\"Undersampled positive reviews (7-10):\")\ntrain_and_evaluate_models(models, X_train_pos_undersampled, y_train_pos_undersampled, X_test_pos_undersampled, y_test_pos_undersampled, 'bow_undersampled_mc4_pos_data')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T17:45:36.745739Z","iopub.execute_input":"2024-10-16T17:45:36.746078Z","iopub.status.idle":"2024-10-16T17:52:53.715731Z","shell.execute_reply.started":"2024-10-16T17:45:36.746038Z","shell.execute_reply":"2024-10-16T17:52:53.714685Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Undersampled negative reviews (1-4):\nTraining Logistic Regression...\nAccuracy: 0.360\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.46      0.49      0.48      2284\n           2       0.28      0.28      0.28      2284\n           3       0.29      0.27      0.28      2284\n           4       0.39      0.40      0.39      2284\n\n    accuracy                           0.36      9136\n   macro avg       0.36      0.36      0.36      9136\nweighted avg       0.36      0.36      0.36      9136\n\n\n\nModel Logistic Regression saved to bow_undersampled_mc4_neg_data/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.363\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.40      0.67      0.50      2284\n           2       0.28      0.15      0.20      2284\n           3       0.30      0.21      0.25      2284\n           4       0.38      0.43      0.40      2284\n\n    accuracy                           0.36      9136\n   macro avg       0.34      0.36      0.34      9136\nweighted avg       0.34      0.36      0.34      9136\n\n\n\nModel Random Forest saved to bow_undersampled_mc4_neg_data/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.362\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.43      0.57      0.49      2284\n           2       0.27      0.23      0.24      2284\n           3       0.31      0.18      0.23      2284\n           4       0.38      0.47      0.42      2284\n\n    accuracy                           0.36      9136\n   macro avg       0.35      0.36      0.35      9136\nweighted avg       0.35      0.36      0.35      9136\n\n\n\nModel Gradient Boosting saved to bow_undersampled_mc4_neg_data/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.343\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.41      0.50      0.45      2284\n           2       0.27      0.27      0.27      2284\n           3       0.29      0.25      0.27      2284\n           4       0.40      0.34      0.37      2284\n\n    accuracy                           0.34      9136\n   macro avg       0.34      0.34      0.34      9136\nweighted avg       0.34      0.34      0.34      9136\n\n\n\nModel Support Vector Machine saved to bow_undersampled_mc4_neg_data/Support_Vector_Machine.joblib\n\nUndersampled positive reviews (7-10):\nTraining Logistic Regression...\nAccuracy: 0.332\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.40      0.35      0.37      2263\n           8       0.27      0.26      0.27      2263\n           9       0.28      0.29      0.28      2263\n          10       0.39      0.42      0.40      2263\n\n    accuracy                           0.33      9052\n   macro avg       0.33      0.33      0.33      9052\nweighted avg       0.33      0.33      0.33      9052\n\n\n\nModel Logistic Regression saved to bow_undersampled_mc4_pos_data/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.355\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.40      0.46      0.43      2263\n           8       0.29      0.13      0.18      2263\n           9       0.30      0.14      0.19      2263\n          10       0.36      0.68      0.47      2263\n\n    accuracy                           0.35      9052\n   macro avg       0.34      0.35      0.32      9052\nweighted avg       0.34      0.35      0.32      9052\n\n\n\nModel Random Forest saved to bow_undersampled_mc4_pos_data/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.354\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.40      0.45      0.42      2263\n           8       0.27      0.15      0.19      2263\n           9       0.29      0.24      0.26      2263\n          10       0.39      0.58      0.46      2263\n\n    accuracy                           0.35      9052\n   macro avg       0.34      0.35      0.34      9052\nweighted avg       0.34      0.35      0.34      9052\n\n\n\nModel Gradient Boosting saved to bow_undersampled_mc4_pos_data/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.325\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.37      0.39      0.38      2263\n           8       0.27      0.27      0.27      2263\n           9       0.27      0.26      0.27      2263\n          10       0.39      0.37      0.38      2263\n\n    accuracy                           0.32      9052\n   macro avg       0.32      0.32      0.32      9052\nweighted avg       0.32      0.32      0.32      9052\n\n\n\nModel Support Vector Machine saved to bow_undersampled_mc4_pos_data/Support_Vector_Machine.joblib\n\n","output_type":"stream"}]},{"cell_type":"code","source":"tfidf = TfidfVectorizer(max_features=20000, stop_words='english')\n\nX_train_neg_tfidf = tfidf.fit_transform(neg_train_df['review'])\nX_test_neg_tfidf = tfidf.transform(neg_test_df['review'])\nX_train_pos_tfidf = tfidf.transform(pos_train_df['review'])\nX_test_pos_tfidf = tfidf.transform(pos_test_df['review'])\n\nwith open('tfidf_dd.pkl', 'wb') as f:\n    pickle.dump(tfidf, f)\n\nprint(\"TF-IDF negative reviews (1-4):\")\ntrain_and_evaluate_models(models, X_train_neg_tfidf, y_train_neg, X_test_neg_tfidf, y_test_neg, 'tfidf_mc4_neg_data')\n\nprint(\"TF-IDF positive reviews (7-10):\")\ntrain_and_evaluate_models(models, X_train_pos_tfidf, y_train_pos, X_test_pos_tfidf, y_test_pos, 'tfidf_mc4_pos_data')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T17:52:53.716884Z","iopub.execute_input":"2024-10-16T17:52:53.717216Z","iopub.status.idle":"2024-10-16T18:05:08.320191Z","shell.execute_reply.started":"2024-10-16T17:52:53.717183Z","shell.execute_reply":"2024-10-16T18:05:08.319241Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"TF-IDF negative reviews (1-4):\nTraining Logistic Regression...\nAccuracy: 0.480\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.55      0.84      0.67      5022\n           2       0.21      0.06      0.10      2302\n           3       0.30      0.15      0.20      2541\n           4       0.43      0.48      0.45      2635\n\n    accuracy                           0.48     12500\n   macro avg       0.37      0.38      0.35     12500\nweighted avg       0.41      0.48      0.42     12500\n\n\n\nModel Logistic Regression saved to tfidf_mc4_neg_data/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.402\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.40      1.00      0.57      5022\n           2       0.00      0.00      0.00      2302\n           3       1.00      0.00      0.00      2541\n           4       0.29      0.00      0.00      2635\n\n    accuracy                           0.40     12500\n   macro avg       0.42      0.25      0.14     12500\nweighted avg       0.43      0.40      0.23     12500\n\n\n\nModel Random Forest saved to tfidf_mc4_neg_data/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.461\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.49      0.90      0.63      5022\n           2       0.21      0.02      0.04      2302\n           3       0.33      0.06      0.11      2541\n           4       0.41      0.39      0.40      2635\n\n    accuracy                           0.46     12500\n   macro avg       0.36      0.34      0.29     12500\nweighted avg       0.39      0.46      0.37     12500\n\n\n\nModel Gradient Boosting saved to tfidf_mc4_neg_data/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.468\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.56      0.80      0.66      5022\n           2       0.22      0.08      0.12      2302\n           3       0.28      0.18      0.22      2541\n           4       0.42      0.45      0.43      2635\n\n    accuracy                           0.47     12500\n   macro avg       0.37      0.38      0.36     12500\nweighted avg       0.41      0.47      0.42     12500\n\n\n\nModel Support Vector Machine saved to tfidf_mc4_neg_data/Support_Vector_Machine.joblib\n\nTF-IDF positive reviews (7-10):\nTraining Logistic Regression...\nAccuracy: 0.447\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.41      0.33      0.36      2307\n           8       0.29      0.24      0.27      2850\n           9       0.25      0.07      0.10      2344\n          10       0.52      0.80      0.63      4999\n\n    accuracy                           0.45     12500\n   macro avg       0.37      0.36      0.34     12500\nweighted avg       0.40      0.45      0.40     12500\n\n\n\nModel Logistic Regression saved to tfidf_mc4_pos_data/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.401\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       1.00      0.00      0.00      2307\n           8       0.38      0.00      0.00      2850\n           9       0.00      0.00      0.00      2344\n          10       0.40      1.00      0.57      4999\n\n    accuracy                           0.40     12500\n   macro avg       0.44      0.25      0.15     12500\nweighted avg       0.43      0.40      0.23     12500\n\n\n\nModel Random Forest saved to tfidf_mc4_pos_data/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.440\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.42      0.25      0.31      2307\n           8       0.30      0.14      0.19      2850\n           9       0.23      0.03      0.05      2344\n          10       0.47      0.89      0.61      4999\n\n    accuracy                           0.44     12500\n   macro avg       0.36      0.33      0.29     12500\nweighted avg       0.38      0.44      0.36     12500\n\n\n\nModel Gradient Boosting saved to tfidf_mc4_pos_data/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.435\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.38      0.34      0.36      2307\n           8       0.28      0.27      0.27      2850\n           9       0.24      0.07      0.10      2344\n          10       0.53      0.75      0.62      4999\n\n    accuracy                           0.44     12500\n   macro avg       0.36      0.36      0.34     12500\nweighted avg       0.39      0.44      0.40     12500\n\n\n\nModel Support Vector Machine saved to tfidf_mc4_pos_data/Support_Vector_Machine.joblib\n\n","output_type":"stream"}]},{"cell_type":"code","source":"tfidf = TfidfVectorizer(max_features=20000, stop_words='english')\n\nX_train_neg_tfidf_undersampled = tfidf.fit_transform(undersampled_neg_train_df['review'])\nX_test_neg_tfidf_undersampled = tfidf.transform(undersampled_neg_test_df['review'])\nX_train_pos_tfidf_undersampled = tfidf.transform(undersampled_pos_train_df['review'])\nX_test_pos_tfidf_undersampled = tfidf.transform(undersampled_pos_test_df['review'])\n\nwith open('tfidf_ud.pkl', 'wb') as f:\n    pickle.dump(tfidf, f)\n\ny_train_neg_tfidf_undersampled = undersampled_neg_train_df['rating']\ny_test_neg_tfidf_undersampled = undersampled_neg_test_df['rating']\ny_train_pos_tfidf_undersampled = undersampled_pos_train_df['rating']\ny_test_pos_tfidf_undersampled = undersampled_pos_test_df['rating']\n\nprint(\"Undersampled TF-IDF negative reviews (1-4):\")\ntrain_and_evaluate_models(models, X_train_neg_tfidf_undersampled, y_train_neg_tfidf_undersampled, X_test_neg_tfidf_undersampled, y_test_neg_tfidf_undersampled, 'utfidf_mc4_neg_data')\n\nprint(\"Undersampled TF-IDF positive reviews (7-10):\")\ntrain_and_evaluate_models(models, X_train_pos_tfidf_undersampled, y_train_pos_tfidf_undersampled, X_test_pos_tfidf_undersampled, y_test_pos_tfidf_undersampled, 'utfidf_mc4_pos_data')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:05:08.321402Z","iopub.execute_input":"2024-10-16T18:05:08.321717Z","iopub.status.idle":"2024-10-16T18:12:55.428839Z","shell.execute_reply.started":"2024-10-16T18:05:08.321683Z","shell.execute_reply":"2024-10-16T18:12:55.427890Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Undersampled TF-IDF negative reviews (1-4):\nTraining Logistic Regression...\nAccuracy: 0.387\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.49      0.54      0.52      2284\n           2       0.30      0.25      0.27      2284\n           3       0.30      0.27      0.28      2284\n           4       0.41      0.49      0.45      2284\n\n    accuracy                           0.39      9136\n   macro avg       0.38      0.39      0.38      9136\nweighted avg       0.38      0.39      0.38      9136\n\n\n\nModel Logistic Regression saved to utfidf_mc4_neg_data/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.357\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.40      0.62      0.49      2284\n           2       0.27      0.15      0.19      2284\n           3       0.29      0.21      0.24      2284\n           4       0.38      0.45      0.41      2284\n\n    accuracy                           0.36      9136\n   macro avg       0.34      0.36      0.33      9136\nweighted avg       0.34      0.36      0.33      9136\n\n\n\nModel Random Forest saved to utfidf_mc4_neg_data/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.358\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.44      0.55      0.49      2284\n           2       0.28      0.19      0.22      2284\n           3       0.28      0.23      0.25      2284\n           4       0.37      0.47      0.41      2284\n\n    accuracy                           0.36      9136\n   macro avg       0.34      0.36      0.34      9136\nweighted avg       0.34      0.36      0.34      9136\n\n\n\nModel Gradient Boosting saved to utfidf_mc4_neg_data/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.378\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.49      0.51      0.50      2284\n           2       0.29      0.27      0.28      2284\n           3       0.30      0.28      0.29      2284\n           4       0.42      0.45      0.43      2284\n\n    accuracy                           0.38      9136\n   macro avg       0.37      0.38      0.38      9136\nweighted avg       0.37      0.38      0.38      9136\n\n\n\nModel Support Vector Machine saved to utfidf_mc4_neg_data/Support_Vector_Machine.joblib\n\nUndersampled TF-IDF positive reviews (7-10):\nTraining Logistic Regression...\nAccuracy: 0.363\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.42      0.45      0.44      2263\n           8       0.28      0.24      0.26      2263\n           9       0.30      0.28      0.29      2263\n          10       0.42      0.48      0.45      2263\n\n    accuracy                           0.36      9052\n   macro avg       0.36      0.36      0.36      9052\nweighted avg       0.36      0.36      0.36      9052\n\n\n\nModel Logistic Regression saved to utfidf_mc4_pos_data/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.350\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.39      0.48      0.43      2263\n           8       0.27      0.14      0.19      2263\n           9       0.27      0.16      0.20      2263\n          10       0.37      0.62      0.46      2263\n\n    accuracy                           0.35      9052\n   macro avg       0.33      0.35      0.32      9052\nweighted avg       0.33      0.35      0.32      9052\n\n\n\nModel Random Forest saved to utfidf_mc4_pos_data/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.362\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.40      0.46      0.43      2263\n           8       0.29      0.20      0.24      2263\n           9       0.30      0.27      0.28      2263\n          10       0.41      0.51      0.46      2263\n\n    accuracy                           0.36      9052\n   macro avg       0.35      0.36      0.35      9052\nweighted avg       0.35      0.36      0.35      9052\n\n\n\nModel Gradient Boosting saved to utfidf_mc4_pos_data/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.357\nClassification Report:\n              precision    recall  f1-score   support\n\n           7       0.41      0.44      0.43      2263\n           8       0.28      0.26      0.27      2263\n           9       0.29      0.28      0.29      2263\n          10       0.42      0.44      0.43      2263\n\n    accuracy                           0.36      9052\n   macro avg       0.35      0.36      0.35      9052\nweighted avg       0.35      0.36      0.35      9052\n\n\n\nModel Support Vector Machine saved to utfidf_mc4_pos_data/Support_Vector_Machine.joblib\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# word embeddings","metadata":{}},{"cell_type":"code","source":"sentences = [text.split() for text in train_df['review']]","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:12:55.429996Z","iopub.execute_input":"2024-10-16T18:12:55.430315Z","iopub.status.idle":"2024-10-16T18:12:55.728286Z","shell.execute_reply.started":"2024-10-16T18:12:55.430283Z","shell.execute_reply":"2024-10-16T18:12:55.727200Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"X_train = train_df['review']\nX_test = train_df['review']\n\ny_train = train_df['rating']\ny_test = test_df['rating']","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:12:55.729628Z","iopub.execute_input":"2024-10-16T18:12:55.729949Z","iopub.status.idle":"2024-10-16T18:12:55.734478Z","shell.execute_reply.started":"2024-10-16T18:12:55.729916Z","shell.execute_reply":"2024-10-16T18:12:55.733543Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def average_word_vectors(words, model, num_features):\n    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n    n_words = 0\n    for word in words:\n        if word in model.wv:\n            n_words += 1\n            feature_vector = np.add(feature_vector, model.wv[word])\n    if n_words > 0:\n        feature_vector = np.divide(feature_vector, n_words)\n    return feature_vector","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:12:55.741585Z","iopub.execute_input":"2024-10-16T18:12:55.741861Z","iopub.status.idle":"2024-10-16T18:12:55.750072Z","shell.execute_reply.started":"2024-10-16T18:12:55.741832Z","shell.execute_reply":"2024-10-16T18:12:55.749267Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def average_glove_vectors(words, embeddings_index, num_features):\n    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n    n_words = 0\n    for word in words:\n        if word in embeddings_index:\n            n_words += 1\n            feature_vector = np.add(feature_vector, embeddings_index[word])\n    if n_words > 0:\n        feature_vector = np.divide(feature_vector, n_words)\n    return feature_vector","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:12:55.751107Z","iopub.execute_input":"2024-10-16T18:12:55.751431Z","iopub.status.idle":"2024-10-16T18:12:55.760503Z","shell.execute_reply.started":"2024-10-16T18:12:55.751400Z","shell.execute_reply":"2024-10-16T18:12:55.759625Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)\nX_train_word2vec = np.array([average_word_vectors(text.split(), word2vec_model, 100) for text in X_train])\nX_test_word2vec = np.array([average_word_vectors(text.split(), word2vec_model, 100) for text in X_test])","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:12:55.761566Z","iopub.execute_input":"2024-10-16T18:12:55.762255Z","iopub.status.idle":"2024-10-16T18:13:27.207248Z","shell.execute_reply.started":"2024-10-16T18:12:55.762214Z","shell.execute_reply":"2024-10-16T18:13:27.206186Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"glove_path = '/kaggle/input/imdb-grinatom/glove.twitter.27B.100d.txt'\nembeddings_index = {}\nwith open(glove_path, 'r', encoding='utf-8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        vector = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = vector\n\nX_train_glove = np.array([average_glove_vectors(text.split(), embeddings_index, 100) for text in X_train])\nX_test_glove = np.array([average_glove_vectors(text.split(), embeddings_index, 100) for text in X_test])","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:13:27.208681Z","iopub.execute_input":"2024-10-16T18:13:27.209022Z","iopub.status.idle":"2024-10-16T18:14:13.859745Z","shell.execute_reply.started":"2024-10-16T18:13:27.208976Z","shell.execute_reply":"2024-10-16T18:14:13.858829Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"fasttext_model = FastText(sentences, vector_size=100, window=5, min_count=5, workers=4)\nX_train_fasttext = np.array([average_word_vectors(text.split(), fasttext_model, 100) for text in X_train])\nX_test_fasttext = np.array([average_word_vectors(text.split(), fasttext_model, 100) for text in X_test])","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:14:13.861104Z","iopub.execute_input":"2024-10-16T18:14:13.861491Z","iopub.status.idle":"2024-10-16T18:15:38.593109Z","shell.execute_reply.started":"2024-10-16T18:14:13.861442Z","shell.execute_reply":"2024-10-16T18:15:38.592300Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_and_evaluate_models(models, X_train_word2vec, y_train, X_test_word2vec, y_test, 'w2v')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:15:38.594357Z","iopub.execute_input":"2024-10-16T18:15:38.594679Z","iopub.status.idle":"2024-10-16T18:29:53.719903Z","shell.execute_reply.started":"2024-10-16T18:15:38.594646Z","shell.execute_reply":"2024-10-16T18:29:53.718851Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Training Logistic Regression...\nAccuracy: 0.280\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.35      0.59      0.44      5022\n           2       0.10      0.01      0.02      2302\n           3       0.15      0.04      0.07      2541\n           4       0.14      0.16      0.15      2635\n           7       0.13      0.10      0.11      2307\n           8       0.19      0.17      0.18      2850\n           9       0.16      0.01      0.01      2344\n          10       0.34      0.55      0.42      4999\n\n    accuracy                           0.28     25000\n   macro avg       0.19      0.20      0.17     25000\nweighted avg       0.23      0.28      0.23     25000\n\n\n\nModel Logistic Regression saved to w2v/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.290\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.34      0.65      0.44      5022\n           2       0.21      0.02      0.04      2302\n           3       0.18      0.04      0.07      2541\n           4       0.17      0.11      0.13      2635\n           7       0.16      0.08      0.11      2307\n           8       0.19      0.19      0.19      2850\n           9       0.19      0.04      0.07      2344\n          10       0.34      0.54      0.41      4999\n\n    accuracy                           0.29     25000\n   macro avg       0.22      0.21      0.18     25000\nweighted avg       0.24      0.29      0.24     25000\n\n\n\nModel Random Forest saved to w2v/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.269\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.34      0.55      0.42      5022\n           2       0.18      0.04      0.07      2302\n           3       0.15      0.07      0.10      2541\n           4       0.14      0.13      0.14      2635\n           7       0.15      0.12      0.13      2307\n           8       0.18      0.16      0.17      2850\n           9       0.15      0.03      0.06      2344\n          10       0.33      0.50      0.40      4999\n\n    accuracy                           0.27     25000\n   macro avg       0.20      0.20      0.18     25000\nweighted avg       0.23      0.27      0.23     25000\n\n\n\nModel Gradient Boosting saved to w2v/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.281\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.35      0.59      0.44      5022\n           2       0.05      0.00      0.00      2302\n           3       0.15      0.04      0.06      2541\n           4       0.14      0.17      0.15      2635\n           7       0.13      0.09      0.11      2307\n           8       0.18      0.18      0.18      2850\n           9       0.25      0.00      0.00      2344\n          10       0.34      0.55      0.42      4999\n\n    accuracy                           0.28     25000\n   macro avg       0.20      0.20      0.17     25000\nweighted avg       0.23      0.28      0.23     25000\n\n\n\nModel Support Vector Machine saved to w2v/Support_Vector_Machine.joblib\n\n","output_type":"stream"}]},{"cell_type":"code","source":"train_and_evaluate_models(models, X_train_glove, y_train, X_test_glove, y_test, 'glove')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:29:53.721049Z","iopub.execute_input":"2024-10-16T18:29:53.721345Z","iopub.status.idle":"2024-10-16T18:43:41.162775Z","shell.execute_reply.started":"2024-10-16T18:29:53.721314Z","shell.execute_reply":"2024-10-16T18:43:41.161722Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Training Logistic Regression...\nAccuracy: 0.285\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.34      0.63      0.44      5022\n           2       0.14      0.01      0.01      2302\n           3       0.16      0.04      0.06      2541\n           4       0.14      0.13      0.13      2635\n           7       0.13      0.09      0.10      2307\n           8       0.19      0.17      0.18      2850\n           9       0.15      0.01      0.02      2344\n          10       0.33      0.56      0.42      4999\n\n    accuracy                           0.28     25000\n   macro avg       0.20      0.20      0.17     25000\nweighted avg       0.23      0.28      0.23     25000\n\n\n\nModel Logistic Regression saved to glove/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.301\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.34      0.70      0.45      5022\n           2       0.24      0.02      0.04      2302\n           3       0.21      0.04      0.06      2541\n           4       0.19      0.09      0.12      2635\n           7       0.18      0.07      0.10      2307\n           8       0.19      0.19      0.19      2850\n           9       0.18      0.03      0.05      2344\n          10       0.33      0.57      0.42      4999\n\n    accuracy                           0.30     25000\n   macro avg       0.23      0.21      0.18     25000\nweighted avg       0.25      0.30      0.23     25000\n\n\n\nModel Random Forest saved to glove/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.278\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.34      0.59      0.43      5022\n           2       0.17      0.04      0.06      2302\n           3       0.17      0.07      0.10      2541\n           4       0.15      0.12      0.13      2635\n           7       0.15      0.11      0.12      2307\n           8       0.19      0.18      0.19      2850\n           9       0.19      0.04      0.07      2344\n          10       0.33      0.51      0.40      4999\n\n    accuracy                           0.28     25000\n   macro avg       0.21      0.21      0.19     25000\nweighted avg       0.24      0.28      0.23     25000\n\n\n\nModel Gradient Boosting saved to glove/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.286\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.34      0.64      0.45      5022\n           2       0.10      0.00      0.00      2302\n           3       0.14      0.03      0.05      2541\n           4       0.13      0.13      0.13      2635\n           7       0.13      0.07      0.09      2307\n           8       0.19      0.19      0.19      2850\n           9       0.50      0.00      0.00      2344\n          10       0.33      0.56      0.42      4999\n\n    accuracy                           0.29     25000\n   macro avg       0.23      0.20      0.17     25000\nweighted avg       0.25      0.29      0.22     25000\n\n\n\nModel Support Vector Machine saved to glove/Support_Vector_Machine.joblib\n\n","output_type":"stream"}]},{"cell_type":"code","source":"train_and_evaluate_models(models, X_train_fasttext, y_train, X_test_fasttext, y_test, 'ft')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:43:41.163941Z","iopub.execute_input":"2024-10-16T18:43:41.164284Z","iopub.status.idle":"2024-10-16T18:58:53.858184Z","shell.execute_reply.started":"2024-10-16T18:43:41.164250Z","shell.execute_reply":"2024-10-16T18:58:53.857267Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Training Logistic Regression...\nAccuracy: 0.277\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.34      0.59      0.43      5022\n           2       0.14      0.01      0.02      2302\n           3       0.14      0.04      0.06      2541\n           4       0.14      0.14      0.14      2635\n           7       0.13      0.10      0.12      2307\n           8       0.18      0.15      0.16      2850\n           9       0.15      0.01      0.01      2344\n          10       0.33      0.56      0.42      4999\n\n    accuracy                           0.28     25000\n   macro avg       0.19      0.20      0.17     25000\nweighted avg       0.22      0.28      0.22     25000\n\n\n\nModel Logistic Regression saved to ft/Logistic_Regression.joblib\n\nTraining Random Forest...\nAccuracy: 0.288\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.33      0.65      0.44      5022\n           2       0.21      0.03      0.05      2302\n           3       0.18      0.04      0.06      2541\n           4       0.17      0.10      0.12      2635\n           7       0.16      0.08      0.10      2307\n           8       0.18      0.18      0.18      2850\n           9       0.18      0.03      0.06      2344\n          10       0.33      0.55      0.41      4999\n\n    accuracy                           0.29     25000\n   macro avg       0.22      0.21      0.18     25000\nweighted avg       0.24      0.29      0.23     25000\n\n\n\nModel Random Forest saved to ft/Random_Forest.joblib\n\nTraining Gradient Boosting...\nAccuracy: 0.266\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.33      0.56      0.42      5022\n           2       0.18      0.04      0.07      2302\n           3       0.14      0.06      0.08      2541\n           4       0.14      0.12      0.13      2635\n           7       0.14      0.10      0.12      2307\n           8       0.18      0.16      0.17      2850\n           9       0.16      0.04      0.06      2344\n          10       0.31      0.50      0.38      4999\n\n    accuracy                           0.27     25000\n   macro avg       0.20      0.20      0.18     25000\nweighted avg       0.22      0.27      0.22     25000\n\n\n\nModel Gradient Boosting saved to ft/Gradient_Boosting.joblib\n\nTraining Support Vector Machine...\nAccuracy: 0.277\nClassification Report:\n              precision    recall  f1-score   support\n\n           1       0.34      0.59      0.43      5022\n           2       0.06      0.00      0.00      2302\n           3       0.14      0.03      0.05      2541\n           4       0.14      0.15      0.15      2635\n           7       0.13      0.08      0.10      2307\n           8       0.17      0.15      0.16      2850\n           9       0.50      0.00      0.00      2344\n          10       0.33      0.57      0.42      4999\n\n    accuracy                           0.28     25000\n   macro avg       0.23      0.20      0.16     25000\nweighted avg       0.25      0.28      0.22     25000\n\n\n\nModel Support Vector Machine saved to ft/Support_Vector_Machine.joblib\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# binary lstm/gru","metadata":{}},{"cell_type":"code","source":"X_train = train_df['review']\nX_test = train_df['review']\n\ny_train = train_df['sentiment']\ny_test = test_df['sentiment']","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:58:53.859251Z","iopub.execute_input":"2024-10-16T18:58:53.859534Z","iopub.status.idle":"2024-10-16T18:58:53.864531Z","shell.execute_reply.started":"2024-10-16T18:58:53.859503Z","shell.execute_reply":"2024-10-16T18:58:53.863505Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# min_samples = y_train.value_counts().min()\n\n# def undersample(df, target_column, min_samples):\n#     undersampled_dfs = []\n#     for rating in df[target_column].unique():\n#         rating_df = df[df[target_column] == rating]\n#         undersampled_df = resample(rating_df, replace=False, n_samples=min_samples, random_state=42)\n#         undersampled_dfs.append(undersampled_df)\n#     return pd.concat(undersampled_dfs)\n\n# undersampled_train_df = undersample(train_df, 'rating', min_samples)\n\n# X_train_undersampled = undersampled_train_df['review']\n# y_train_undersampled = undersampled_train_df['rating']\n\n# undersampled_test_df = undersample(test_df, 'rating', min_samples)\n\n# X_test_undersampled = undersampled_test_df['review']\n# y_test_undersampled = undersampled_test_df['rating']","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:58:53.865750Z","iopub.execute_input":"2024-10-16T18:58:53.866050Z","iopub.status.idle":"2024-10-16T18:58:53.877478Z","shell.execute_reply.started":"2024-10-16T18:58:53.866019Z","shell.execute_reply":"2024-10-16T18:58:53.876568Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=20000, oov_token='OOV')\ntokenizer.fit_on_texts(X_train)\n\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq = tokenizer.texts_to_sequences(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:58:53.878603Z","iopub.execute_input":"2024-10-16T18:58:53.878881Z","iopub.status.idle":"2024-10-16T18:58:59.704864Z","shell.execute_reply.started":"2024-10-16T18:58:53.878851Z","shell.execute_reply":"2024-10-16T18:58:59.704066Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"with open('tokenizer.pkl', 'wb') as handle:\n    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:58:59.705977Z","iopub.execute_input":"2024-10-16T18:58:59.706311Z","iopub.status.idle":"2024-10-16T18:58:59.764108Z","shell.execute_reply.started":"2024-10-16T18:58:59.706277Z","shell.execute_reply":"2024-10-16T18:58:59.763406Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"max_length = 128\nX_train_padded = pad_sequences(X_train_seq, maxlen=max_length, padding='post', truncating='post')\nX_test_padded = pad_sequences(X_test_seq, maxlen=max_length, padding='post', truncating='post')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:58:59.765062Z","iopub.execute_input":"2024-10-16T18:58:59.765360Z","iopub.status.idle":"2024-10-16T18:59:00.212326Z","shell.execute_reply.started":"2024-10-16T18:58:59.765327Z","shell.execute_reply":"2024-10-16T18:59:00.211523Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:59:00.213389Z","iopub.execute_input":"2024-10-16T18:59:00.213690Z","iopub.status.idle":"2024-10-16T18:59:00.229064Z","shell.execute_reply.started":"2024-10-16T18:59:00.213658Z","shell.execute_reply":"2024-10-16T18:59:00.228083Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def create_lstm_model(vocab_size, embedding_dim, max_length):\n    model = Sequential()\n    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n    model.add(LSTM(32, return_sequences=False))\n    model.add(Dropout(0.1))\n    model.add(Dense(16, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'mse'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:59:00.230264Z","iopub.execute_input":"2024-10-16T18:59:00.230616Z","iopub.status.idle":"2024-10-16T18:59:00.241087Z","shell.execute_reply.started":"2024-10-16T18:59:00.230584Z","shell.execute_reply":"2024-10-16T18:59:00.240275Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def create_gru_model(vocab_size, embedding_dim, max_length):\n    model = Sequential()\n    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n    model.add(GRU(32, return_sequences=False))\n    model.add(Dropout(0.1))\n    model.add(Dense(16, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'mse'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:59:00.242090Z","iopub.execute_input":"2024-10-16T18:59:00.242361Z","iopub.status.idle":"2024-10-16T18:59:00.252231Z","shell.execute_reply.started":"2024-10-16T18:59:00.242330Z","shell.execute_reply":"2024-10-16T18:59:00.251373Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def train_and_evaluate_binary_models(models, X_train, y_train, X_test, y_test, epochs=1, batch_size=64, save_dir=None):\n    if save_dir and not os.path.exists(save_dir):\n        os.makedirs(save_dir)\n    \n    for name, model_fn in models.items():\n        print(f\"Training {name}...\")\n\n        model = model_fn()\n\n        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=2)\n\n        loss, accuracy, mse = model.evaluate(X_test, y_test)\n        print(f\"{name} Test Accuracy: {accuracy:.3f}\")\n        print(f\"{name} Test MSE: {mse:.3f}\")\n\n        y_pred = model.predict(X_test)\n        y_pred_classes = (y_pred > 0.5).astype(int).flatten()\n        print(\"Classification Report:\")\n        print(classification_report(y_test, y_pred_classes))\n        \n        if save_dir:\n            model_path = os.path.join(save_dir, f'{name}_model.h5')\n            model.save(model_path)\n            print(f\"{name} saved to {model_path}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:59:00.253356Z","iopub.execute_input":"2024-10-16T18:59:00.255307Z","iopub.status.idle":"2024-10-16T18:59:00.265058Z","shell.execute_reply.started":"2024-10-16T18:59:00.255271Z","shell.execute_reply":"2024-10-16T18:59:00.264245Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"vocab_size = 20000\nembedding_dim = 100\n\nmodels = {\n    'LSTM': lambda: create_lstm_model(vocab_size, embedding_dim, max_length),\n    'GRU': lambda: create_gru_model(vocab_size, embedding_dim, max_length)\n}","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:59:00.266025Z","iopub.execute_input":"2024-10-16T18:59:00.267775Z","iopub.status.idle":"2024-10-16T18:59:00.279072Z","shell.execute_reply.started":"2024-10-16T18:59:00.267731Z","shell.execute_reply":"2024-10-16T18:59:00.278326Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"train_and_evaluate_binary_models(models, X_train_padded, y_train_encoded, X_test_padded, y_test_encoded, epochs=5, batch_size=4, save_dir='binary_models')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T18:59:00.280216Z","iopub.execute_input":"2024-10-16T18:59:00.280490Z","iopub.status.idle":"2024-10-16T19:09:08.792258Z","shell.execute_reply.started":"2024-10-16T18:59:00.280461Z","shell.execute_reply":"2024-10-16T19:09:08.791368Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Training LSTM...\nEpoch 1/5\n6250/6250 - 64s - 10ms/step - accuracy: 0.5579 - loss: 0.6709 - mse: 0.2393 - val_accuracy: 0.7170 - val_loss: 0.5387 - val_mse: 0.1795\nEpoch 2/5\n6250/6250 - 59s - 9ms/step - accuracy: 0.8494 - loss: 0.3692 - mse: 0.1129 - val_accuracy: 0.9201 - val_loss: 0.2185 - val_mse: 0.0609\nEpoch 3/5\n6250/6250 - 59s - 9ms/step - accuracy: 0.9142 - loss: 0.2261 - mse: 0.0645 - val_accuracy: 0.9616 - val_loss: 0.1324 - val_mse: 0.0326\nEpoch 4/5\n6250/6250 - 59s - 9ms/step - accuracy: 0.9512 - loss: 0.1395 - mse: 0.0375 - val_accuracy: 0.9815 - val_loss: 0.0776 - val_mse: 0.0168\nEpoch 5/5\n6250/6250 - 59s - 9ms/step - accuracy: 0.9773 - loss: 0.0757 - mse: 0.0187 - val_accuracy: 0.9909 - val_loss: 0.0327 - val_mse: 0.0075\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.0344 - mse: 0.0083\nLSTM Test Accuracy: 0.991\nLSTM Test MSE: 0.008\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99     12500\n           1       0.99      0.99      0.99     12500\n\n    accuracy                           0.99     25000\n   macro avg       0.99      0.99      0.99     25000\nweighted avg       0.99      0.99      0.99     25000\n\nLSTM saved to binary_models/LSTM_model.h5\n\nTraining GRU...\nEpoch 1/5\n6250/6250 - 60s - 10ms/step - accuracy: 0.6623 - loss: 0.5493 - mse: 0.1898 - val_accuracy: 0.9146 - val_loss: 0.2289 - val_mse: 0.0646\nEpoch 2/5\n6250/6250 - 59s - 9ms/step - accuracy: 0.9102 - loss: 0.2334 - mse: 0.0682 - val_accuracy: 0.9665 - val_loss: 0.1138 - val_mse: 0.0282\nEpoch 3/5\n6250/6250 - 59s - 9ms/step - accuracy: 0.9593 - loss: 0.1203 - mse: 0.0323 - val_accuracy: 0.9875 - val_loss: 0.0508 - val_mse: 0.0107\nEpoch 4/5\n6250/6250 - 58s - 9ms/step - accuracy: 0.9827 - loss: 0.0524 - mse: 0.0134 - val_accuracy: 0.9958 - val_loss: 0.0159 - val_mse: 0.0034\nEpoch 5/5\n6250/6250 - 58s - 9ms/step - accuracy: 0.9926 - loss: 0.0242 - mse: 0.0058 - val_accuracy: 0.9982 - val_loss: 0.0068 - val_mse: 0.0015\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0063 - mse: 0.0014\nGRU Test Accuracy: 0.998\nGRU Test MSE: 0.001\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     12500\n           1       1.00      1.00      1.00     12500\n\n    accuracy                           1.00     25000\n   macro avg       1.00      1.00      1.00     25000\nweighted avg       1.00      1.00      1.00     25000\n\nGRU saved to binary_models/GRU_model.h5\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# regression lstm/gru","metadata":{}},{"cell_type":"code","source":"def create_lstm_mc_model(vocab_size, embedding_dim, max_length):\n    model = Sequential()\n    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n    model.add(LSTM(32, return_sequences=False))\n    model.add(Dropout(0.1))\n    model.add(Dense(16, activation='relu'))\n    model.add(Dense(4, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mse'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:09:08.793953Z","iopub.execute_input":"2024-10-16T19:09:08.794379Z","iopub.status.idle":"2024-10-16T19:09:08.800793Z","shell.execute_reply.started":"2024-10-16T19:09:08.794324Z","shell.execute_reply":"2024-10-16T19:09:08.799809Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def create_gru_mc_model(vocab_size, embedding_dim, max_length):\n    model = Sequential()\n    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n    model.add(GRU(32, return_sequences=False))\n    model.add(Dropout(0.1))\n    model.add(Dense(16, activation='relu'))\n    model.add(Dense(4, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'mse'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:09:08.801982Z","iopub.execute_input":"2024-10-16T19:09:08.802346Z","iopub.status.idle":"2024-10-16T19:09:08.816420Z","shell.execute_reply.started":"2024-10-16T19:09:08.802313Z","shell.execute_reply":"2024-10-16T19:09:08.815497Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"def prepare_labels(ratings):\n    classes = []\n    for rating in ratings:\n        if rating in [1, 2, 3, 4]:\n            classes.append(rating - 1)\n        elif rating in [7, 8, 9, 10]:\n            classes.append(rating - 7)\n    return to_categorical(classes, num_classes=4)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:09:08.817520Z","iopub.execute_input":"2024-10-16T19:09:08.817838Z","iopub.status.idle":"2024-10-16T19:09:08.833323Z","shell.execute_reply.started":"2024-10-16T19:09:08.817807Z","shell.execute_reply":"2024-10-16T19:09:08.832478Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def tokenize_and_pad(X_train, X_test, num_words=20000, max_length=128):\n    tokenizer = Tokenizer(num_words=num_words)\n    tokenizer.fit_on_texts(X_train)\n    \n    X_train_seq = tokenizer.texts_to_sequences(X_train)\n    X_test_seq = tokenizer.texts_to_sequences(X_test)\n    \n    X_train_padded = pad_sequences(X_train_seq, maxlen=max_length, padding='post', truncating='post')\n    X_test_padded = pad_sequences(X_test_seq, maxlen=max_length, padding='post', truncating='post')\n    \n    return X_train_padded, X_test_padded, tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:09:08.834457Z","iopub.execute_input":"2024-10-16T19:09:08.834740Z","iopub.status.idle":"2024-10-16T19:09:08.845943Z","shell.execute_reply.started":"2024-10-16T19:09:08.834710Z","shell.execute_reply":"2024-10-16T19:09:08.845064Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"y_train_neg = prepare_labels(train_df[train_df['rating'].between(1, 4)]['rating'])\ny_train_pos = prepare_labels(train_df[train_df['rating'].between(7, 10)]['rating'])\n\ny_test_neg = prepare_labels(test_df[test_df['rating'].between(1, 4)]['rating'])\ny_test_pos = prepare_labels(test_df[test_df['rating'].between(7, 10)]['rating'])","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:09:08.847022Z","iopub.execute_input":"2024-10-16T19:09:08.847336Z","iopub.status.idle":"2024-10-16T19:09:08.882984Z","shell.execute_reply.started":"2024-10-16T19:09:08.847305Z","shell.execute_reply":"2024-10-16T19:09:08.882320Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"X_train_neg = train_df[train_df['rating'].between(1, 4)]['review']\nX_test_neg = test_df[test_df['rating'].between(1, 4)]['review']\nX_train_pos = train_df[train_df['rating'].between(7, 10)]['review']\nX_test_pos = test_df[test_df['rating'].between(7, 10)]['review']","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:09:08.884090Z","iopub.execute_input":"2024-10-16T19:09:08.884448Z","iopub.status.idle":"2024-10-16T19:09:08.895026Z","shell.execute_reply.started":"2024-10-16T19:09:08.884408Z","shell.execute_reply":"2024-10-16T19:09:08.894201Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"X_train_neg_padded, X_test_neg_padded, neg_tokenizer = tokenize_and_pad(X_train_neg, X_test_neg)\n\nX_train_pos_padded, X_test_pos_padded, pos_tokenizer = tokenize_and_pad(X_train_pos, X_test_pos)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:09:08.896155Z","iopub.execute_input":"2024-10-16T19:09:08.896447Z","iopub.status.idle":"2024-10-16T19:09:15.660180Z","shell.execute_reply.started":"2024-10-16T19:09:08.896416Z","shell.execute_reply":"2024-10-16T19:09:15.659376Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"models = {\n    'LSTM': lambda: create_lstm_mc_model(vocab_size, embedding_dim, max_length),\n    'GRU': lambda: create_gru_mc_model(vocab_size, embedding_dim, max_length)\n}","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:09:15.661712Z","iopub.execute_input":"2024-10-16T19:09:15.662039Z","iopub.status.idle":"2024-10-16T19:09:15.666729Z","shell.execute_reply.started":"2024-10-16T19:09:15.661994Z","shell.execute_reply":"2024-10-16T19:09:15.665847Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"def train_and_evaluate_mc_models(models, X_train, y_train, X_test, y_test, epochs=1, batch_size=64, save_dir=None):\n    if save_dir and not os.path.exists(save_dir):\n        os.makedirs(save_dir)\n    \n    for name, model_fn in models.items():\n        print(f\"Training {name}...\")\n\n        model = model_fn()\n\n        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=2)\n\n        loss, accuracy, mse = model.evaluate(X_test, y_test)\n        print(f\"{name} Test Accuracy: {accuracy:.3f}\")\n        print(f\"{name} Test MSE: {mse:.3f}\")\n\n        y_pred = model.predict(X_test)\n        y_pred_classes = np.argmax(y_pred, axis=1)\n        y_true_classes = np.argmax(y_test, axis=1)\n\n        print(\"Classification Report:\")\n        print(classification_report(y_true_classes, y_pred_classes))\n\n        if save_dir:\n            model_path = os.path.join(save_dir, f'{name}_model.h5')\n            model.save(model_path)\n            print(f\"{name} saved to {model_path}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:09:15.667755Z","iopub.execute_input":"2024-10-16T19:09:15.668045Z","iopub.status.idle":"2024-10-16T19:09:15.678297Z","shell.execute_reply.started":"2024-10-16T19:09:15.667993Z","shell.execute_reply":"2024-10-16T19:09:15.677502Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"train_and_evaluate_mc_models(models, X_train_neg_padded, y_train_neg, X_test_neg_padded, y_test_neg, epochs=5, batch_size=4, save_dir='binary_neg_models')\n\ntrain_and_evaluate_mc_models(models, X_train_pos_padded, y_train_pos, X_test_pos_padded, y_test_pos, epochs=5, batch_size=4, save_dir='binary_pos_models')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T19:09:15.679405Z","iopub.execute_input":"2024-10-16T19:09:15.679702Z","iopub.status.idle":"2024-10-16T19:19:58.396170Z","shell.execute_reply.started":"2024-10-16T19:09:15.679671Z","shell.execute_reply":"2024-10-16T19:19:58.395335Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Training LSTM...\nEpoch 1/5\n3125/3125 - 33s - 10ms/step - accuracy: 0.4084 - loss: 1.3224 - mse: 0.1786 - val_accuracy: 0.4089 - val_loss: 1.3213 - val_mse: 0.1784\nEpoch 2/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.4580 - loss: 1.2614 - mse: 0.1702 - val_accuracy: 0.4034 - val_loss: 1.3687 - val_mse: 0.1837\nEpoch 3/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.5224 - loss: 1.1173 - mse: 0.1508 - val_accuracy: 0.4154 - val_loss: 1.3893 - val_mse: 0.1810\nEpoch 4/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.5926 - loss: 0.9453 - mse: 0.1259 - val_accuracy: 0.4431 - val_loss: 1.4597 - val_mse: 0.1816\nEpoch 5/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.6736 - loss: 0.7596 - mse: 0.1013 - val_accuracy: 0.4320 - val_loss: 1.6511 - val_mse: 0.1915\n\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4297 - loss: 1.6433 - mse: 0.1905\nLSTM Test Accuracy: 0.432\nLSTM Test MSE: 0.192\n\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.56      0.67      0.61      5022\n           1       0.26      0.21      0.23      2302\n           2       0.29      0.31      0.30      2541\n           3       0.39      0.30      0.34      2635\n\n    accuracy                           0.43     12500\n   macro avg       0.38      0.37      0.37     12500\nweighted avg       0.42      0.43      0.42     12500\n\nLSTM saved to binary_neg_models/LSTM_model.h5\n\nTraining GRU...\nEpoch 1/5\n3125/3125 - 33s - 10ms/step - accuracy: 0.4078 - loss: 1.3247 - mse: 0.1789 - val_accuracy: 0.4017 - val_loss: 1.3226 - val_mse: 0.1786\nEpoch 2/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.4692 - loss: 1.2229 - mse: 0.1647 - val_accuracy: 0.4590 - val_loss: 1.2326 - val_mse: 0.1647\nEpoch 3/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.6031 - loss: 0.9389 - mse: 0.1256 - val_accuracy: 0.4517 - val_loss: 1.3506 - val_mse: 0.1732\nEpoch 4/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.7037 - loss: 0.6937 - mse: 0.0943 - val_accuracy: 0.4256 - val_loss: 1.6324 - val_mse: 0.1899\nEpoch 5/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.7798 - loss: 0.5209 - mse: 0.0728 - val_accuracy: 0.3973 - val_loss: 2.0344 - val_mse: 0.2061\n\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4031 - loss: 2.0304 - mse: 0.2044\nGRU Test Accuracy: 0.397\nGRU Test MSE: 0.206\n\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.62      0.52      0.56      5022\n           1       0.21      0.32      0.26      2302\n           2       0.27      0.28      0.28      2541\n           3       0.41      0.35      0.38      2635\n\n    accuracy                           0.40     12500\n   macro avg       0.38      0.37      0.37     12500\nweighted avg       0.43      0.40      0.41     12500\n\nGRU saved to binary_neg_models/GRU_model.h5\n\nTraining LSTM...\nEpoch 1/5\n3125/3125 - 33s - 11ms/step - accuracy: 0.3782 - loss: 1.3384 - mse: 0.1809 - val_accuracy: 0.3859 - val_loss: 1.3568 - val_mse: 0.1836\nEpoch 2/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.4221 - loss: 1.3011 - mse: 0.1758 - val_accuracy: 0.3979 - val_loss: 1.3438 - val_mse: 0.1813\nEpoch 3/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.5003 - loss: 1.1564 - mse: 0.1555 - val_accuracy: 0.4058 - val_loss: 1.3696 - val_mse: 0.1823\nEpoch 4/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.5978 - loss: 0.9461 - mse: 0.1259 - val_accuracy: 0.4218 - val_loss: 1.4623 - val_mse: 0.1876\nEpoch 5/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.6886 - loss: 0.7505 - mse: 0.1004 - val_accuracy: 0.4230 - val_loss: 1.6840 - val_mse: 0.1990\n\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4279 - loss: 1.6826 - mse: 0.1975\nLSTM Test Accuracy: 0.423\nLSTM Test MSE: 0.199\n\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.35      0.35      0.35      2307\n           1       0.32      0.28      0.30      2850\n           2       0.28      0.18      0.22      2344\n           3       0.53      0.66      0.58      4999\n\n    accuracy                           0.42     12500\n   macro avg       0.37      0.36      0.36     12500\nweighted avg       0.40      0.42      0.41     12500\n\nLSTM saved to binary_pos_models/LSTM_model.h5\n\nTraining GRU...\nEpoch 1/5\n3125/3125 - 33s - 10ms/step - accuracy: 0.3786 - loss: 1.3393 - mse: 0.1811 - val_accuracy: 0.3966 - val_loss: 1.3228 - val_mse: 0.1787\nEpoch 2/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.4485 - loss: 1.2553 - mse: 0.1694 - val_accuracy: 0.4198 - val_loss: 1.3147 - val_mse: 0.1768\nEpoch 3/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.5875 - loss: 0.9692 - mse: 0.1291 - val_accuracy: 0.4273 - val_loss: 1.4223 - val_mse: 0.1843\nEpoch 4/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.7000 - loss: 0.7036 - mse: 0.0941 - val_accuracy: 0.3874 - val_loss: 1.7960 - val_mse: 0.2074\nEpoch 5/5\n3125/3125 - 31s - 10ms/step - accuracy: 0.7882 - loss: 0.5058 - mse: 0.0690 - val_accuracy: 0.3914 - val_loss: 2.1877 - val_mse: 0.2229\n\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3945 - loss: 2.1726 - mse: 0.2207\nGRU Test Accuracy: 0.391\nGRU Test MSE: 0.223\n\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.34      0.36      0.35      2307\n           1       0.29      0.32      0.30      2850\n           2       0.24      0.19      0.21      2344\n           3       0.54      0.54      0.54      4999\n\n    accuracy                           0.39     12500\n   macro avg       0.35      0.35      0.35     12500\nweighted avg       0.39      0.39      0.39     12500\n\nGRU saved to binary_pos_models/GRU_model.h5\n\n","output_type":"stream"}]}]}